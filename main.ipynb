{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3f2ddf",
   "metadata": {},
   "source": [
    "# IMAGE CLASSIFICATION CNN IN PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3582c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e191d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2374fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d59b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e88338b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d6f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "116e6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)# 3 input channels, 12 output channels, 5x5 kernel and returns 28x28 (28 - 5 + 1) -> (12, 28, 28)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 2x2 pooling to reduce size by half (28 / 2 = 14) -> (12, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5) # 12 input channels, 24 output channels, 5x5 kernel and returns 10x10 (14 - 5 + 1) -> (24, 10, 10)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)# 24 input channels (10x10), 120 output features\n",
    "        # 24 * 5 * 5 = 600, because after the second conv layer and pooling, the size is (24, 5, 5)\n",
    "        self.fc2 = nn.Linear(120, 84)# 120 input features, 84 output features\n",
    "        # 84 is a common size for the hidden layer in neural networks\n",
    "        # It is not a fixed rule, but it is often used as a good size for hidden layers\n",
    "        # It is a balance between having enough capacity to learn complex patterns and not being too large to overfit\n",
    "        self.fc3 = nn.Linear(84, 10)# 84 input features, 10 output features (one for each class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))# 3 input channels, 12 output channels, 5x5 kernel and returns 28x28 (28 - 5 + 1) -> (12, 28, 28)\n",
    "        # Apply ReLU activation function to introduce non-linearity\n",
    "        x = self.pool(F.relu(self.conv2(x)))# 12 input channels, 24 output channels, 5x5 kernel and returns 10x10 (14 - 5 + 1) -> (24, 10, 10)\n",
    "        # Apply ReLU activation function to introduce non-linearity\n",
    "        x = torch.flatten(x, 1) # Flatten the tensor to a 2D tensor (batch_size, 24 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x)) # Apply ReLU activation function to the first fully connected layer\n",
    "        x = F.relu(self.fc2(x)) # Apply ReLU activation function to the second fully connected layer\n",
    "        x = self.fc3(x) # Output layer, no activation function applied here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de2cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss() # Cross entropy loss for multi-class classification\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # Stochastic Gradient Descent optimizer with learning rate 0.001 and momentum 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df30f1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0...\n",
      "loss: 2.1473\n",
      "training epoch 1...\n",
      "loss: 1.6974\n",
      "training epoch 2...\n",
      "loss: 1.5022\n",
      "training epoch 3...\n",
      "loss: 1.3897\n",
      "training epoch 4...\n",
      "loss: 1.3046\n",
      "training epoch 5...\n",
      "loss: 1.2302\n",
      "training epoch 6...\n",
      "loss: 1.1575\n",
      "training epoch 7...\n",
      "loss: 1.0992\n",
      "training epoch 8...\n",
      "loss: 1.0476\n",
      "training epoch 9...\n",
      "loss: 1.0023\n",
      "training epoch 10...\n",
      "loss: 0.9623\n",
      "training epoch 11...\n",
      "loss: 0.9244\n",
      "training epoch 12...\n",
      "loss: 0.8915\n",
      "training epoch 13...\n",
      "loss: 0.8566\n",
      "training epoch 14...\n",
      "loss: 0.8262\n",
      "training epoch 15...\n",
      "loss: 0.7997\n",
      "training epoch 16...\n",
      "loss: 0.7708\n",
      "training epoch 17...\n",
      "loss: 0.7451\n",
      "training epoch 18...\n",
      "loss: 0.7162\n",
      "training epoch 19...\n",
      "loss: 0.6935\n",
      "training epoch 20...\n",
      "loss: 0.6695\n",
      "training epoch 21...\n",
      "loss: 0.6447\n",
      "training epoch 22...\n",
      "loss: 0.6258\n",
      "training epoch 23...\n",
      "loss: 0.6033\n",
      "training epoch 24...\n",
      "loss: 0.5791\n",
      "training epoch 25...\n",
      "loss: 0.5573\n",
      "training epoch 26...\n",
      "loss: 0.5398\n",
      "training epoch 27...\n",
      "loss: 0.5137\n",
      "training epoch 28...\n",
      "loss: 0.4955\n",
      "training epoch 29...\n",
      "loss: 0.4770\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):  # Loop over the dataset multiple times\n",
    "    print(f'training epoch {epoch}...')\n",
    "    \n",
    "    running_loss = 0.0 # Initialize running loss for the epoch\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data # Get the inputs and labels from the data loader\n",
    "        optimizer.zero_grad() # Zero the parameter gradients to prevent accumulation from previous iterations\n",
    "        \n",
    "        outputs = net(inputs)  # Forward pass to get the model outputs\n",
    "        loss = loss_function(outputs, labels) # Calculate the loss using the outputs and labels\n",
    "        loss.backward()  # Backward pass to compute gradients\n",
    "        optimizer.step()  # Update weights using the optimizer\n",
    "        \n",
    "        running_loss += loss.item()  # Accumulate the loss for this batch\n",
    "        \n",
    "    print(f'loss: {running_loss / len(train_loader):.4f}')  # Print the average loss for the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3929568",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'cifar10_neural_net.pth')  # Save the trained model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc86f09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "net.load_state_dict(torch.load('cifar10_neural_net.pth'))  # Load the saved model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49c175de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 68.90%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for inference and memory efficiency\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)  # Forward pass to get the model outputs\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get the predicted class with the highest score\n",
    "        total += labels.size(0)  # Increment total count of images\n",
    "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "        \n",
    "accuracy = 100 * correct / total  # Calculate accuracy as a percentage\n",
    "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')  # Print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70963b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: dog\n",
      "Predicted class: ship\n",
      "Predicted class: frog\n"
     ]
    }
   ],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize the image to 32x32\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image\n",
    "])\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)  # Open the image file\n",
    "    image = new_transform(image)  # Apply the transformations\n",
    "    image = image.unsqueeze(0)  # Add a batch dimension (1, 3, 32, 32)\n",
    "    return image\n",
    "\n",
    "\n",
    "image_paths = [\n",
    "    'IMG1.jpg',\n",
    "    'IMG2.jpeg', \n",
    "    'IMG3.jpg',\n",
    "]\n",
    "images = [load_image(img) for img in image_paths]\n",
    "\n",
    "\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    for img in images:\n",
    "        outputs = net(img)  # Forward pass to get the model outputs\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get the predicted class with the highest score\n",
    "        print(f'Predicted class: {class_names[predicted.item()]}')  # Print the predicted class name "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
